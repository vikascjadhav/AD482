from pathlib import Path

from labs.grading import Default as GuidedExercise
from labs.common.userinterface import Console
from ad482.common import prechecks, steps, grading
from .common.constants import FILES_DIR, KAFKA_CONNECT_CLUSTER_NAME


class ConnectIntegration(GuidedExercise):
    __LAB__ = "connect-integration"

    """
    Integration Lab
    """
    repair_requests_topic_name = "repair-request.events"
    repair_requests_db_instance_name = "postgresql-repair-requests"
    plumbers_db_instance_name = "postgresql-plumbers"
    postgresql_db_name = "waterleakdb"
    repair_requests_connector_name = 'repair-requests-connector'
    incidents_connector_name = 'incidents-connector'

    def start(self):
        prechecks.verify_config()
        items = [
            steps.pull_apps_repo(),
            steps.copy_lab_files(f"{self.__LAB__}/apps", self.__LAB__),
            steps.copy_env_file(Path(self.__LAB__, "plumber-service")),
            steps.check_ocp_api(),
            steps.check_ocp_credentials(),
            steps.check_kafka_connection(),
            steps.move_to_kafka_cluster_namespace(),
            steps.create_topics(
                [self.repair_requests_topic_name]
            ),
            steps.create_postgresql_from_file(
                self.repair_requests_db_instance_name,
                self.postgresql_db_name,
                FILES_DIR.joinpath(self.__LAB__,
                                   "postgresql-repair-requests.sql")
            ),
            steps.create_postgresql_from_file(
                self.plumbers_db_instance_name,
                self.postgresql_db_name,
                FILES_DIR.joinpath(self.__LAB__,
                                   "postgresql-plumbers.sql")
            ),
            steps.create_elasticsearch_cluster("elasticsearch")
        ]
        Console(items).run_items(action="Starting")

    def finish(self):
        items = [
            steps.check_ocp_api(),
            steps.check_ocp_credentials(),
            steps.move_to_kafka_cluster_namespace(False),
            steps.delete_connect_connectors(
                [self.repair_requests_connector_name,
                 self.incidents_connector_name]),
            steps.delete_connect_cluster(KAFKA_CONNECT_CLUSTER_NAME),
            steps.delete_topics(
                ['my-connect-cluster-configs', 'my-connect-cluster-offsets',
                 'my-connect-cluster-status',
                 self.repair_requests_topic_name]
            ),
            steps.delete_postgresql(self.repair_requests_db_instance_name),
            steps.delete_postgresql(self.plumbers_db_instance_name),
            steps.delete_elasticsearch_cluster("elasticsearch"),
        ]
        Console(items).run_items(action="Finishing")

    def grade(self):
        items = [
            grading.check_connect_cluster_specifications(
                KAFKA_CONNECT_CLUSTER_NAME,
                {
                    "metadata.annotations["
                    "'strimzi.io/use-connector-resources']": "true",
                    "metadata.name": KAFKA_CONNECT_CLUSTER_NAME,
                    "spec.config['key.converter']":
                        "org.apache.kafka.connect.storage.StringConverter",
                    "spec.config['value.converter']":
                        "org.apache.kafka.connect.storage.StringConverter",
                    "spec.replicas": 1,
                }),
            grading.check_connect_connector_specifications(
                self.repair_requests_connector_name,
                {
                    "metadata.labels['strimzi.io/cluster']":
                        KAFKA_CONNECT_CLUSTER_NAME,
                    "metadata.name": self.repair_requests_connector_name,
                    "spec.config['plugin.name']": "pgoutput",
                    "spec.config['database.hostname']":
                        "postgresql-repair-requests",
                    "spec.config['database.port']": 5432,
                    "spec.config['schema.include.list']": "public",
                    "spec.config['table.include.list']": "public.outboxevent",
                    "spec.config['tombstones.on.delete']": False,
                    "spec.config['transforms']": "EventRouter",
                    "spec.config['transforms.EventRouter.type']":
                        "io.debezium.transforms.outbox.EventRouter",
                    "spec.config['transforms.EventRouter.table.fields"
                    ".additional.placement']": "type:header:eventType",
                    "spec.config['transforms.EventRouter.route.topic"
                    ".replacement']": "${routedByValue}.events",
                }),
            grading.check_connect_connector_specifications(
                self.incidents_connector_name,
                {
                    "metadata.labels['strimzi.io/cluster']":
                        KAFKA_CONNECT_CLUSTER_NAME,
                    "metadata.name": self.incidents_connector_name,
                    "spec.config['camel.sink.endpoint.operation']": "Index",
                    "spec.config['camel.sink.endpoint.indexName']":
                        "incidents",
                    "spec.config['key.converter']":
                        "org.apache.kafka.connect.json.JsonConverter",
                    "spec.config['value.converter']":
                        "org.apache.kafka.connect.json.JsonConverter",
                    "spec.config['key.converter.schemas.enable']": False,
                    "spec.config['value.converter.schemas.enable']": False,
                    "spec.config['topics']": "repair-request.events",
                }),
            grading.verify_has_records_with_json_value(
                self.repair_requests_topic_name,
                [{"id": 1, "status": "CREATED", "plumberId": 1},
                 {"id": 2, "status": "CREATED", "plumberId": 2}]
            ),
        ]
        Console(items).run_items(action="Grading")
