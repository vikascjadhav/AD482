from labs.grading import Default as GuidedExercise
from labs.common.userinterface import Console
from ad482.common import prechecks, steps
from .common.constants import KUBEFILES_DIR, KAFKA_CONNECT_CLUSTER_NAME


class ConnectTransformation(GuidedExercise):
    __LAB__ = "connect-transformation"

    """
    Message Transformation Guided Exercise
    """

    def start(self):
        prechecks.verify_config()
        items = [
            steps.pull_apps_repo(),
            steps.copy_lab_files(f"{self.__LAB__}/apps", self.__LAB__),
            steps.check_ocp_api(),
            steps.check_ocp_credentials(),
            steps.move_to_kafka_cluster_namespace(),
            steps.check_kafka_connection(),
            steps.create_topics(
                ['postgre-accountants']
            ),
            # Read from file maybe next round?
            steps.create_postgresql("postgresql", "accountantsdb",
                                    "CREATE TABLE accountants ("
                                    "id serial PRIMARY KEY,"
                                    "username VARCHAR ( 50 ) NOT NULL,"
                                    "ssn INTEGER UNIQUE NOT NULL"
                                    ");"
                                    "CREATE SEQUENCE "
                                    "hibernate_sequence START 1;"),
            steps.create_elasticsearch_cluster("elasticsearch"),
            steps.create_connect_cluster(KAFKA_CONNECT_CLUSTER_NAME,
                                         "quay.io/redhattraining/ad482-"
                                         "ch05s06-connect-cluster:latest"),
            steps.apply_resource(
                KUBEFILES_DIR.joinpath('connect_transformation',
                                       'jdbc-source-connector.yaml'),
                None,
                label="Creating JDBC source connector"
            ),
            steps.apply_resource(
                KUBEFILES_DIR.joinpath('connect_transformation',
                                       'es-sink-connector.yaml'),
                None,
                label="Creating Elasticsearch sink connector"
            )
        ]
        Console(items).run_items(action="Starting")

    def finish(self):
        items = [
            steps.check_ocp_api(),
            steps.check_ocp_credentials(),
            steps.move_to_kafka_cluster_namespace(False),
            steps.delete_connect_connectors(['jdbc-source-connector',
                                             'elasticsearch-sink-connector']),
            steps.delete_connect_cluster(KAFKA_CONNECT_CLUSTER_NAME),
            steps.delete_topics(
                ['my-connect-cluster-configs', 'my-connect-cluster-offsets',
                 'my-connect-cluster-status', 'postgre-accountants']
            ),
            steps.delete_elasticsearch_cluster("elasticsearch"),
            steps.delete_postgresql("postgresql")
        ]
        Console(items).run_items(action="Finishing")
